# 'Scrapy Parser Pep' created by Pavel.
```
https://github.com/pgphil86
```
![image](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue)
### Languages:
### I. [Русский язык.]()
### II. [English language.]()
## I. Проект 'Scrapy Parser Pep'.

### Описание проекта.
Это парсер, который позволяет собирать данные о документах PEP, ведёт счёт документов PEP, а так же сохранять результаты в csv файлах. 
### Работа с проектом.
Для начала необходимо клонировать репозиторий и зайти в рабочую директорию проекта.
```
git@github.com:pgphil86/scrapy_parser_pep.git
```
```
cd scrapy_parser_pep
```
Далее создаем и активируем виртуальное окружение.
```
python3 -m venv venv
```
```
source venv/bin/activate
```
После устанавливаем зависимости из requirements.txt.
```
python3 -m pip install --upgrade pip
```
```
pip install -r requirements.txt
```
Теперь мы можем запускать проект.
```
scrapy crawl pep
```
[Вверх.]()
## II. 'Scrapy Parser Pep'.

### Description of the project.
This is a parser that allows you to collect data about PEP documents, keep track of PEP documents, as well as save the results in csv files.
### Working with the project.
First, you need to clone the repository and go to the working directory of the project.
```
git@github.com:pgphil86/scrapy_parser_pep.git
```
```
cd scrapy_parser_pep
```
Next, we create and activate a virtual environment.
```
python3 -m venv venv
```
```
source venv/bin/activate
```
Then set the settings from requirements.txt.
```
python3 -m pip install --upgrade pip
```
```
pip install -r requirements.txt
```
Now we can start the project.
```
scrapy crawl pep
```
[Up.]()
